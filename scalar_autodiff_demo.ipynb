{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from autodiff import assign, value, d, exp, ln, Variable, Expression, Argument\n",
    "import math\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import batched\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Logistic Regression using Scalar Autodiff\n",
    "\n",
    "In this demo, we will make a logistic regression model using just the scalar functionality in the autodiff module.\n",
    "\n",
    "We will start by making the sigmoid function two different ways. Even though the module already has the sigmoid function (under the name \"logistic\"), I will recreate it here for demonstration purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Making a sigmoid function using existing functionality\n",
    "\n",
    "The sigmoid function can easily be made using existing operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_sigmoid(arg):\n",
    "    \"\"\"\n",
    "    A Sigmoid function made using the autodiff module\n",
    "    \"\"\"\n",
    "    return 1 / (1 + exp(-arg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6224593312018546\n",
      "0.2350037122015945\n"
     ]
    }
   ],
   "source": [
    "x = Variable('x')\n",
    "y = naive_sigmoid(x)\n",
    "dydx = d(y, x)\n",
    "with assign(x=0.5):\n",
    "    print(value(y))\n",
    "    print(value(dydx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works just fine, but ignores one of the biggest benefits of the sigmoid function: the easily calculated derivative. If the above is used, the derivative will be calculated explicitly, i.e. using the formula\n",
    "\n",
    "$$\\frac{d}{dx}\\frac{1}{1+e^{-x}} = -\\left(1+e^{-x}\\right)^{-2} * -e^{-x}$$\n",
    "\n",
    "However, the derivative of the sigmoid function can be stated and calculated much more efficiently in its implicit form:\n",
    "\n",
    "$$\\frac{d}{dx}\\text{sigmoid}(x) = \\text{sigmoid}(x)(1-\\text{sigmoid}(x))$$\n",
    "\n",
    "To take advantage of this, a custom class needs to be made for the sigmoid function where the implicit derivative written can be implemented as a method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Making a sigmoid function custom class\n",
    "\n",
    "An example ```Sigmoid``` class is shown below with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sigmoid(x):\n",
    "    \"\"\"\n",
    "    Helper function which implements the sigmoid function\n",
    "    \"\"\"\n",
    "    # Writing such a helper function is not necessary, but it does make the below code a little cleaner.\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "\n",
    "class Sigmoid(Expression):  # Your custom expression class must subclass the \"Expression\" abstract class\n",
    "    \"\"\"\n",
    "    A class which implements the Sigmoid function, AKA the Logistic function.\n",
    "    \"\"\"\n",
    "\n",
    "    # The arguments of the expression need to be declared as class variables, like below\n",
    "    arg = Argument()\n",
    "    \n",
    "    # A constructor does not need to be implemented. By default, the constructor will take in a number of expressions equal to the number of arguments created above.\n",
    "    # So in this example, the Sigmoid class will have one argument, like Sigmoid(x)\n",
    "\n",
    "    # The \"_get_value\" method needs to be implemented for each expression type\n",
    "    def _get_value(self):\n",
    "        # Here, write the value that the expression should have\n",
    "        return _sigmoid(self.arg.val)  # To get the value of any argument, use the \".val\" property\n",
    "    \n",
    "    # For each argument, use the \".derivate\" decorator to register a function that returns the derivative of the expression with respect to the given argument\n",
    "    @arg.derivative\n",
    "    def derivative(self):\n",
    "        # In this case, the derivative of sigmoid(x) with respect to x is sigmoid(x) * (1 - sigmoid(x))\n",
    "        # For implicit derivatives like this, self.val can be used, like below\n",
    "        return self.val * (1 - self.val)\n",
    "    \n",
    "    # The last function that must be implemented the _make_str method, which will be used in the __str__ overload for the expression.\n",
    "    def _make_str(self) -> str:\n",
    "        # This function should return a string representing the expression.\n",
    "        return f\"sigmoid({self.arg._str})\"\n",
    "        # To reference string representations of arguments, use \"._str\" instead of using the \"str\" function directly\n",
    "        # This is because the \"str\" function will add an extra suffix to the representation with the value of the expression.\n",
    "        # For example, if this function returned f\"sigmoid({self.arg})\" by mistake, the expression would look something like:\n",
    "        #   sigmoid(x=1)=0.7310585786300049\n",
    "        # instead of\n",
    "        #   sigmoid(x)=0.7310585786300049\n",
    "\n",
    "\n",
    "# I also recommend writing a global function to more easily use the custom class on expressions and also have a handy sigmoid function for use on regular numerical data\n",
    "def sigmoid(arg):\n",
    "    return Sigmoid(arg) if isinstance(arg, Expression) else _sigmoid(arg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Using the sigmoid class to create and train a logistic regression model\n",
    "\n",
    "Now that the sigmoid function is implemented, it can be used to create a logistic regression model. First, we obtain some data, courtesy of UCI, and prepare it for use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease = fetch_ucirepo(id=45)\n",
    "X: pd.DataFrame = heart_disease.data.features\n",
    "y: pd.Series = heart_disease.data.targets\n",
    "\n",
    "# Drop rows with na's\n",
    "incomplete_rows = X.isna().any(axis=1)\n",
    "X = X[~incomplete_rows]\n",
    "y = y[~incomplete_rows]\n",
    "\n",
    "# One hot encoding the multinomial categorical features\n",
    "var_data: pd.DataFrame = heart_disease.variables\n",
    "categorical = var_data[var_data['type'] == 'Categorical']['name']\n",
    "multinomial = [col for col in categorical if X[col].nunique() > 2]\n",
    "X_ohe = pd.get_dummies(data=X, columns=multinomial)\n",
    "\n",
    "# Standard scaling all the columns\n",
    "X_scaled = (X_ohe - X_ohe.mean()) / X_ohe.std()\n",
    "\n",
    "# Adding a column for the bias\n",
    "X_scaled['bias'] = 1\n",
    "\n",
    "# Turning y binary based on presence or absence of heart disease\n",
    "y_bin = y['num'].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a train-test split\n",
    "rng = np.random.default_rng(seed=0)\n",
    "\n",
    "# Start by shuffling idxs\n",
    "permutation = rng.permutation(len(X))\n",
    "\n",
    "# Then choose 80% of those to be in training\n",
    "train_prop = 0.8\n",
    "train_size = int(train_prop * len(X))\n",
    "\n",
    "choices = np.zeros((len(X),))\n",
    "train_idxs = permutation[:train_size]\n",
    "test_idxs = permutation[train_size:]\n",
    "\n",
    "X_train = X_scaled.iloc[train_idxs]\n",
    "X_test = X_scaled.iloc[test_idxs]\n",
    "y_train = y_bin.iloc[train_idxs]\n",
    "y_test = y_bin.iloc[test_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can make a class for the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressor:\n",
    "    \"\"\"\n",
    "    Logistic regression model\n",
    "    Not implemented efficiently because it uses backprop to calculate the gradient\n",
    "    This is for demonstration purposes\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epochs=100, batch_size=20, learning_rate=0.1, seed=0, convergence_threshold=1e-3):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - epochs (int): Number of epochs to use in training\n",
    "        - batch size (int): minibatch size for gradient descent\n",
    "        - learning rate (float): learning rate for gradient descent\n",
    "        - seed (int): rng seed for constructing minibatches\n",
    "        - convergence threshold (float): if the L2 norm of the gradient is less than this threshold, the training can end early\n",
    "        \"\"\"\n",
    "\n",
    "        # Store hyperparams\n",
    "        self._epochs = epochs\n",
    "        self._batch_size = batch_size\n",
    "        self._learning_rate = learning_rate\n",
    "        self._rng = np.random.default_rng(seed=seed)\n",
    "        self._convergence_thresh = convergence_threshold\n",
    "\n",
    "        # Make attrs to hold variables\n",
    "        self._vars = []\n",
    "        self._target_var = Variable('target')\n",
    "        self._weight_vars = []\n",
    "\n",
    "        # Make list to hold weights\n",
    "        self._weights = []\n",
    "\n",
    "        # Make attrs for linear combination and the final prediction after applying sigmoid to linear prediction\n",
    "        self._linear = None\n",
    "        self._pred_exp = None\n",
    "\n",
    "    def fit(self, data: pd.DataFrame, target: pd.Series):\n",
    "        # initialize all variables and expressions for autodiff\n",
    "        self._vars = [Variable(f'x_{col}') for col in data.columns]\n",
    "        self._weight_vars = [Variable(f'w_{col}') for col in data.columns]\n",
    "        self._linear = sum(weight * var for weight, var in zip(self._vars, self._weight_vars))\n",
    "        self._pred_exp = Sigmoid(self._linear)\n",
    "\n",
    "        # initialize weights to 1\n",
    "        self._weights = [1] * len(data.columns)\n",
    "\n",
    "        # The log likelihood formula for logistic regression can be greatly simplified for efficiency\n",
    "        # but for this demo I will show that autodiff can find it \"the hard way\"\n",
    "        ll_exp = self._target_var * ln(self._pred_exp) + (1 - self._target_var) * ln(1 - self._pred_exp)\n",
    "        derivs = [d(ll_exp, weight) for weight in self._weight_vars]\n",
    "\n",
    "        # Do the training using gradient ascent\n",
    "        # Store average log likelihood for each epoch\n",
    "        loglikelies = []\n",
    "\n",
    "        # Loop through epochs\n",
    "        for _ in range(self._epochs):\n",
    "\n",
    "            # Store all log likelihoos for this epoch to average them later\n",
    "            epoch_lls = []\n",
    "\n",
    "            # Make permutation of the data for minibatches\n",
    "            perm = self._rng.permutation(len(data))\n",
    "\n",
    "            # Loop through batches\n",
    "            for batch_idxs in batched(perm, n=self._batch_size):\n",
    "\n",
    "                # This list will store the gradient at the end\n",
    "                gradient = [0 for weight in self._weights]\n",
    "\n",
    "                # loop through batch\n",
    "                for idx in batch_idxs:\n",
    "                    # Assign input, weights, and target value\n",
    "                    assignments = (\n",
    "                        {f\"x_{col}\": val for col, val in data.iloc[idx].to_dict().items()}\n",
    "                        | {f\"w_{col}\": weight for col, weight in zip(data.columns, self._weights)}\n",
    "                        | {'target': target.iloc[idx]}\n",
    "                    )\n",
    "                    with assign(**assignments):\n",
    "                        # Find gradient using LL expression\n",
    "                        try:\n",
    "                            epoch_lls.append(value(ll_exp))\n",
    "                            deriv_vals = [value(deriv) for deriv in derivs]\n",
    "                            gradient = [grad + update for grad, update in zip(gradient, deriv_vals)]\n",
    "                        \n",
    "                        # If there is an domain or overflow error, throw away the datapoint\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "                        except OverflowError:\n",
    "                            pass\n",
    "\n",
    "                # Average batch gradient\n",
    "                gradient = [grad / len(gradient) for grad in gradient]\n",
    "\n",
    "                # If the L2 norm of the gradient is below the threshold, end training\n",
    "                if sum(grad**2 for grad in gradient)**0.5 < self._convergence_thresh:\n",
    "                    break\n",
    "\n",
    "                # Update weights\n",
    "                self._weights = [weight + self._learning_rate * grad for weight, grad in zip(self._weights, gradient)]\n",
    "            \n",
    "            # Average epoch log likelihoods\n",
    "            loglikelies.append(sum(epoch_lls) / len(epoch_lls))\n",
    "        \n",
    "        return loglikelies\n",
    "\n",
    "    def predict(self, data: pd.DataFrame):\n",
    "        # This will store the predictions\n",
    "        preds = []\n",
    "\n",
    "        # Loop through input rows\n",
    "        for _, row in data.iterrows():\n",
    "            # Assign all inputs and weights\n",
    "            assignments = (\n",
    "                {f\"x_{col}\": val for col, val in row.to_dict().items()}\n",
    "                | {f\"w_{col}\": weight for col, weight in zip(data.columns, self._weights)}\n",
    "            )\n",
    "            with assign(**assignments):\n",
    "                # Calculate prediction probability\n",
    "                try:\n",
    "                    pred_prob = value(self._pred_exp)\n",
    "                # If there is an overflow error with the prediction prob, just use the sign of the linear part as a backup\n",
    "                except OverflowError:\n",
    "                    pred_prob = int(value(self._linear) > 0)\n",
    "                preds.append(pred_prob)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the class is created, we can use it to make a regressor and gather metrics on the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LogisticRegressor(epochs=50, learning_rate=0.1)\n",
    "loglikelies = regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22a809f3f50>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loglikelies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the testing data to gather metrics on the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs = regressor.predict(X_test)\n",
    "thresh = 0.5\n",
    "preds = [int(prob > thresh) for prob in pred_probs]\n",
    "rights = [pred == ans for pred, ans in zip(preds, y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "print(f\"Testing accuracy: {sum(rights) / len(rights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
